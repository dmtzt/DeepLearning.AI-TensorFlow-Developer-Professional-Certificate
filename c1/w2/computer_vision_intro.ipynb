{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0AjwMCIL8saqEGmZkpo6b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmtzt/DeepLearning.AI-TensorFlow-Developer-Professional-Certificate/blob/main/c1/w2/computer_vision_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Computer Vision"
      ],
      "metadata": {
        "id": "lrnJV4naTcWT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5dGSt0DSRGu",
        "outputId": "198acc17-925c-4f4c-9978-f7248c52245f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "Fashion MNIST is available as a dataset with an API call in Tensorflow\n",
        "\n",
        "- 60,000 images to train the network\n",
        "- 10,000 images to test the network\n",
        "\n",
        "### Labels\n",
        "The labels describing the images are numbers, mainly for 2 reasons:\n",
        "1. Computers do better with numbers than with texts\n",
        "2. Bias towards a specific language is reduced "
      ],
      "metadata": {
        "id": "tiNgA1B8TxP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TEMtkSGTktj",
        "outputId": "7a13359f-21af-49d9-a747-ed9d1b814548"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 42\n",
        "\n",
        "np.set_printoptions(linewidth=320)\n",
        "\n",
        "print('LABEL:', train_labels[index])\n",
        "print('IMAGE:\\n', train_images[index])\n",
        "\n",
        "plt.imshow(train_images[index], cmap='Greys')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "_aRn_x2Z66Ct",
        "outputId": "8c233526-d2b0-4260-af48-623a79b962c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 9\n",
            "IMAGE:\n",
            " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  82 187  26   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 179 240 237 255 240 139  83  64  43  60  54   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0  58 239 222 234 238 246 252 254 255 248 255 187   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   3   0   0 194 239 226 237 235 232 230 234 234 233 249 171   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   0   0  10 255 226 242 239 238 239 240 239 242 238 248 192   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 172 245 229 240 241 240 241 243 243 241 227 250 209   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   6   5   0  62 255 230 236 239 241 242 241 242 242 238 238 242 253   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3   0   0 255 235 228 244 241 241 244 243 243 244 243 239 235 255  22   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 246 228 220 245 243 237 241 242 242 242 243 239 237 235 253 106   0]\n",
            " [  0   0   3   4   4   2   1   0   0  18 243 228 231 241 243 237 238 242 241 240 240 240 235 237 236 246 234   0]\n",
            " [  1   0   0   0   0   0   0   0  22 255 238 227 238 239 237 241 241 237 236 238 239 239 239 239 239 237 255   0]\n",
            " [  0   0   0   0   0  25  83 168 255 225 225 235 228 230 227 225 227 231 232 237 240 236 238 239 239 235 251  62]\n",
            " [  0 165 225 220 224 255 255 233 229 223 227 228 231 232 235 237 233 230 228 230 233 232 235 233 234 235 255  58]\n",
            " [ 52 251 221 226 227 225 225 225 226 226 225 227 231 229 232 239 245 250 251 252 254 254 252 254 252 235 255   0]\n",
            " [ 31 208 230 233 233 237 236 236 241 235 241 247 251 254 242 236 233 227 219 202 193 189 186 181 171 165 190  42]\n",
            " [ 77 199 172 188 199 202 218 219 220 229 234 222 213 209 207 210 203 184 152 171 165 162 162 167 168 157 192  78]\n",
            " [  0  45 101 140 159 174 182 186 185 188 195 197 188 175 133  70  19   0   0 209 231 218 222 224 227 217 229  93]\n",
            " [  0   0   0   0   0   0   2  24  37  45  32  18  11   0   0   0   0   0   0  72  51  53  37  34  29  31   5   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f90b28957c0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization\n",
        "Neural networks for image processing work better with normalized data"
      ],
      "metadata": {
        "id": "fjl8Hyes75km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "Nl78mG788Fhm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback\n",
        "- Implements a function called by the callback when an epoch ends\n",
        "- In this case, the training is canceled if the loss is below a threshold"
      ],
      "metadata": {
        "id": "N1aTmGfT_j4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if (logs.get('loss') < 0.4):\n",
        "      print('\\nLoss is low, cancel training')\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "Flxw8W7e_mgr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = MyCallback()"
      ],
      "metadata": {
        "id": "PW7lD-8OAUcE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "### First layer\n",
        "`Flatten` takes the 28x28 image square and turns it into a simple linear array.\n",
        "\n",
        "### Last layer\n",
        "The last layer has 10 neurons because there are 10 classes of clothing in the dataset."
      ],
      "metadata": {
        "id": "fQSWMaRNUXZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "x0oWc0bCTuqB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Rn7LtHYWUtjy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "KqIoAENT_jpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyHof3R58p-4",
        "outputId": "9f01904b-1459-41d7-fa85-b6caab8be42d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1859/1875 [============================>.] - ETA: 0s - loss: 0.3381 - accuracy: 0.8755\n",
            "Loss is low, cancel training\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3382 - accuracy: 0.8754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f90b1c80c40>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXJubrFe8tct",
        "outputId": "4c49a967-f8d3-4393-f03a-6b9d16f505b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3627 - accuracy: 0.8661\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3627217411994934, 0.866100013256073]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oIwgTp3V85Wz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}